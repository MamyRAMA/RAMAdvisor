{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c4e4c4",
   "metadata": {},
   "source": [
    "# Tests RAMAdvisor - API Gemini avec Système d'Atypicité V3\n",
    "\n",
    "Ce notebook est organisé en 3 parties :\n",
    "1. **Test de la clé API** - Validation de la connexion Gemini\n",
    "2. **Test normal** - Requête standard avec prompt v3\n",
    "3. **Jeu d'essai** - 5 profils clients différents pour tester le score d'atypicité"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4052b3",
   "metadata": {},
   "source": [
    "## Partie 1 : Test de la Clé API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer la librairie Gemini (Google Generative AI)\n",
    "!pip install --upgrade google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "913ecefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Tester l'API Gemini avec ta clé API\n",
    "import google.generativeai as genai\n",
    "\n",
    "API_KEY = \"AIzaSyCH5PqnZ-OGuVsrSit966K0IDCfperG7u8\"\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Exemple de génération de texte\n",
    "\n",
    "model_light = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "model_experimental = genai.GenerativeModel(\"learnlm-2.0-flash-experimental\")\n",
    "\n",
    "response = model_light.generate_content('Dis bonjour en français !')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c074d",
   "metadata": {},
   "source": [
    "## Partie 2 : Test Normal - Requête Standard avec Prompt V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normal - Client standard avec objectif typique\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Configuration de l'API (utiliser variable d'environnement si possible)\n",
    "API_KEY = os.getenv('GEMINI_API_KEY', \"AIzaSyCH5PqnZ-OGuVsrSit966K0IDCfperG7u8\")\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Client test standard\n",
    "client_standard = {\n",
    "    \"objectif\": \"Je souhaite préparer ma retraite en constituant un patrimoine pour compléter ma pension\",\n",
    "    \"profil_risque\": \"Équilibré\",\n",
    "    \"montant_initial\": \"20000€\",\n",
    "    \"montant_mensuel\": \"600€\",\n",
    "    \"horizon\": \"15 ans\"\n",
    "}\n",
    "\n",
    "print(\"=== TEST NORMAL - CLIENT STANDARD ===\")\n",
    "for key, value in client_standard.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Charger le template v3 et la knowledge base\n",
    "with open('prompt_template_v3.md', 'r', encoding='utf-8') as f:\n",
    "    prompt_template_v3 = f.read()\n",
    "\n",
    "with open('knowledge_base.txt', 'r', encoding='utf-8') as f:\n",
    "    knowledge = f.read()\n",
    "\n",
    "# Fonction de filtrage\n",
    "def filter_knowledge_by_risk(profil_risque, knowledge_content):\n",
    "    risk_objectives = {\n",
    "        \"Prudent\": [\"PRESERVATION\", \"REVENU\"],\n",
    "        \"Équilibré\": [\"REVENU\", \"CROISSANCE_MODEREE\"], \n",
    "        \"Audacieux\": [\"CROISSANCE\", \"CROISSANCE_AGGRESSIVE\"]\n",
    "    }\n",
    "    \n",
    "    relevant_objectives = risk_objectives.get(profil_risque, [\"CROISSANCE_MODEREE\"])\n",
    "    sections = knowledge_content.split(\"OBJECTIF :\")\n",
    "    filtered = []\n",
    "    \n",
    "    for section in sections[1:]:\n",
    "        section_content = \"OBJECTIF :\" + section\n",
    "        for objective in relevant_objectives:\n",
    "            if objective in section_content:\n",
    "                filtered.append(section_content)\n",
    "                break\n",
    "        if len(filtered) >= 2:\n",
    "            break\n",
    "    \n",
    "    return \"\\n\\n\".join(filtered)\n",
    "\n",
    "# Génération du prompt\n",
    "filtered_knowledge = filter_knowledge_by_risk(client_standard[\"profil_risque\"], knowledge)\n",
    "personalized_prompt = prompt_template_v3.format(**client_standard)\n",
    "final_prompt = f\"{personalized_prompt}\\n\\nAllocations de référence :\\n{filtered_knowledge}\"\n",
    "\n",
    "print(f\"\\nLongueur du prompt: {len(final_prompt)} caractères\")\n",
    "print(f\"Sections KB utilisées: {len(filtered_knowledge.split('OBJECTIF :'))-1}\")\n",
    "\n",
    "# Appel Gemini\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "response = model.generate_content(final_prompt)\n",
    "\n",
    "print(\"\\n=== RÉPONSE GEMINI - TEST NORMAL ===\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da40793",
   "metadata": {},
   "source": [
    "## Partie 3 : Jeu d'Essai - 5 Profils Clients Différents\n",
    "\n",
    "Test du système d'atypicité avec des objectifs variés pour valider les scores 1-10 et l'adaptation de l'IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa52be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeu d'essai - 5 clients avec différents niveaux d'atypicité\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Configuration API\n",
    "API_KEY = os.getenv('GEMINI_API_KEY', \"AIzaSyCH5PqnZ-OGuVsrSit966K0IDCfperG7u8\")\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# 5 profils clients avec objectifs de différents niveaux d'atypicité\n",
    "clients_test = [\n",
    "    {\n",
    "        \"nom\": \"Client 1 - Ultra-typique (Score attendu: 9-10)\",\n",
    "        \"objectif\": \"Préparer ma retraite en constituant un patrimoine diversifié\",\n",
    "        \"profil_risque\": \"Équilibré\",\n",
    "        \"montant_initial\": \"25000€\",\n",
    "        \"montant_mensuel\": \"500€\",\n",
    "        \"horizon\": \"20 ans\"\n",
    "    },\n",
    "    {\n",
    "        \"nom\": \"Client 2 - Typique avec nuance (Score attendu: 7-8)\",\n",
    "        \"objectif\": \"Constituer un patrimoine pour ma retraite en privilégiant l'immobilier et l'investissement responsable\",\n",
    "        \"profil_risque\": \"Prudent\",\n",
    "        \"montant_initial\": \"30000€\",\n",
    "        \"montant_mensuel\": \"800€\",\n",
    "        \"horizon\": \"18 ans\"\n",
    "    },\n",
    "    {\n",
    "        \"nom\": \"Client 3 - Moyennement typique (Score attendu: 5-6)\",\n",
    "        \"objectif\": \"Financer les études de mes enfants tout en préparant ma retraite avec une approche équilibrée\",\n",
    "        \"profil_risque\": \"Équilibré\",\n",
    "        \"montant_initial\": \"15000€\",\n",
    "        \"montant_mensuel\": \"600€\",\n",
    "        \"horizon\": \"12 ans\"\n",
    "    },\n",
    "    {\n",
    "        \"nom\": \"Client 4 - Peu typique (Score attendu: 3-4)\",\n",
    "        \"objectif\": \"Investir uniquement dans des actifs éthiques et durables pour financer mon tour du monde dans 8 ans\",\n",
    "        \"profil_risque\": \"Audacieux\",\n",
    "        \"montant_initial\": \"40000€\",\n",
    "        \"montant_mensuel\": \"1200€\",\n",
    "        \"horizon\": \"8 ans\"\n",
    "    },\n",
    "    {\n",
    "        \"nom\": \"Client 5 - Ultra-atypique (Score attendu: 1-2)\",\n",
    "        \"objectif\": \"Générer des revenus passifs maximaux pour devenir financièrement indépendant et quitter mon emploi dans 5 ans\",\n",
    "        \"profil_risque\": \"Audacieux\",\n",
    "        \"montant_initial\": \"100000€\",\n",
    "        \"montant_mensuel\": \"3000€\",\n",
    "        \"horizon\": \"5 ans\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Fonctions utilitaires\n",
    "def load_templates_and_knowledge():\n",
    "    with open('prompt_template_v3.md', 'r', encoding='utf-8') as f:\n",
    "        template = f.read()\n",
    "    with open('knowledge_base.txt', 'r', encoding='utf-8') as f:\n",
    "        knowledge = f.read()\n",
    "    return template, knowledge\n",
    "\n",
    "def filter_knowledge_by_risk(profil_risque, knowledge_content):\n",
    "    risk_objectives = {\n",
    "        \"Prudent\": [\"PRESERVATION\", \"REVENU\"],\n",
    "        \"Équilibré\": [\"REVENU\", \"CROISSANCE_MODEREE\"], \n",
    "        \"Audacieux\": [\"CROISSANCE\", \"CROISSANCE_AGGRESSIVE\"]\n",
    "    }\n",
    "    \n",
    "    relevant_objectives = risk_objectives.get(profil_risque, [\"CROISSANCE_MODEREE\"])\n",
    "    sections = knowledge_content.split(\"OBJECTIF :\")\n",
    "    filtered = []\n",
    "    \n",
    "    for section in sections[1:]:\n",
    "        section_content = \"OBJECTIF :\" + section\n",
    "        for objective in relevant_objectives:\n",
    "            if objective in section_content:\n",
    "                filtered.append(section_content)\n",
    "                break\n",
    "        if len(filtered) >= 2:\n",
    "            break\n",
    "    \n",
    "    return \"\\n\\n\".join(filtered)\n",
    "\n",
    "def test_client(client_data, template, knowledge):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST: {client_data['nom']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Objectif: {client_data['objectif']}\")\n",
    "    print(f\"Profil: {client_data['profil_risque']}\")\n",
    "    print(f\"Montant initial: {client_data['montant_initial']}\")\n",
    "    print(f\"Épargne mensuelle: {client_data['montant_mensuel']}\")\n",
    "    print(f\"Horizon: {client_data['horizon']}\")\n",
    "    \n",
    "    # Préparation du prompt\n",
    "    filtered_knowledge = filter_knowledge_by_risk(client_data[\"profil_risque\"], knowledge)\n",
    "    personalized_prompt = template.format(**client_data)\n",
    "    final_prompt = f\"{personalized_prompt}\\n\\nAllocations de référence :\\n{filtered_knowledge}\"\n",
    "    \n",
    "    print(f\"\\nLongueur prompt: {len(final_prompt)} caractères\")\n",
    "    \n",
    "    # Appel Gemini\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "    response = model.generate_content(final_prompt)\n",
    "    \n",
    "    # Extraction du score d'atypicité de la réponse (si présent)\n",
    "    response_text = response.text\n",
    "    if \"Score attribué\" in response_text:\n",
    "        lines = response_text.split('\\n')\n",
    "        for line in lines:\n",
    "            if \"Score attribué\" in line:\n",
    "                print(f\"✅ {line.strip()}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\n📊 RÉPONSE (premiers 400 caractères):\")\n",
    "    print(response_text[:400] + \"...\" if len(response_text) > 400 else response_text)\n",
    "    print(f\"\\n🔍 Recherche de mots-clés d'adaptation:\")\n",
    "    \n",
    "    # Analyse rapide du niveau d'adaptation\n",
    "    adaptation_keywords = [\"strictement\", \"adapter\", \"personnalisé\", \"dévier\", \"ajuster\"]\n",
    "    found_keywords = [kw for kw in adaptation_keywords if kw.lower() in response_text.lower()]\n",
    "    if found_keywords:\n",
    "        print(f\"Mots-clés trouvés: {', '.join(found_keywords)}\")\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "# Exécution des tests\n",
    "print(\"🚀 DÉBUT DU JEU D'ESSAI - 5 CLIENTS DIFFÉRENTS\")\n",
    "print(\"Objectif: Valider le système de score d'atypicité et l'adaptation de l'IA\")\n",
    "\n",
    "template, knowledge = load_templates_and_knowledge()\n",
    "\n",
    "# Test de chaque client\n",
    "results = []\n",
    "for client in clients_test:\n",
    "    try:\n",
    "        result = test_client(client, template, knowledge)\n",
    "        results.append({\"client\": client[\"nom\"], \"success\": True, \"response_length\": len(result)})\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERREUR pour {client['nom']}: {str(e)}\")\n",
    "        results.append({\"client\": client[\"nom\"], \"success\": False, \"error\": str(e)})\n",
    "\n",
    "# Résumé final\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"📋 RÉSUMÉ DU JEU D'ESSAI\")\n",
    "print(f\"{'='*60}\")\n",
    "for result in results:\n",
    "    status = \"✅ OK\" if result[\"success\"] else \"❌ ERREUR\"\n",
    "    length = f\"({result.get('response_length', 0)} car.)\" if result[\"success\"] else \"\"\n",
    "    print(f\"{status} {result['client']} {length}\")\n",
    "\n",
    "print(f\"\\n🎯 Tests réussis: {sum(1 for r in results if r['success'])}/{len(results)}\")\n",
    "print(\"✅ JEU D'ESSAI TERMINÉ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
