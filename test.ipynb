{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c4e4c4",
   "metadata": {},
   "source": [
    "# Tests RAMAdvisor - API Gemini avec Syst√®me d'Atypicit√© V3\n",
    "\n",
    "Ce notebook est organis√© en 3 parties :\n",
    "1. **Test de la cl√© API** - Validation de la connexion Gemini\n",
    "2. **Test normal** - Requ√™te standard avec prompt v3\n",
    "3. **Jeu d'essai** - 5 profils clients diff√©rents pour tester le score d'atypicit√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4052b3",
   "metadata": {},
   "source": [
    "## Partie 1 : Test de la Cl√© API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer la librairie Gemini (Google Generative AI)\n",
    "!pip install --upgrade google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "913ecefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Tester l'API Gemini avec ta cl√© API\n",
    "import google.generativeai as genai\n",
    "\n",
    "API_KEY = \"AIzaSyCH5PqnZ-OGuVsrSit966K0IDCfperG7u8\"\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Exemple de g√©n√©ration de texte\n",
    "\n",
    "model_light = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "model_experimental = genai.GenerativeModel(\"learnlm-2.0-flash-experimental\")\n",
    "\n",
    "response = model_light.generate_content('Dis bonjour en fran√ßais !')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c074d",
   "metadata": {},
   "source": [
    "## Partie 2 : Test Normal - Requ√™te Standard avec Prompt V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normal - Client standard avec objectif typique\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Configuration de l'API (utiliser variable d'environnement si possible)\n",
    "API_KEY = os.getenv('GEMINI_API_KEY', \"AIzaSyCH5PqnZ-OGuVsrSit966K0IDCfperG7u8\")\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Client test standard\n",
    "client_standard = {\n",
    "    \"objectif\": \"Je souhaite pr√©parer ma retraite en constituant un patrimoine pour compl√©ter ma pension\",\n",
    "    \"profil_risque\": \"√âquilibr√©\",\n",
    "    \"montant_initial\": \"20000‚Ç¨\",\n",
    "    \"montant_mensuel\": \"600‚Ç¨\",\n",
    "    \"horizon\": \"15 ans\"\n",
    "}\n",
    "\n",
    "print(\"=== TEST NORMAL - CLIENT STANDARD ===\")\n",
    "for key, value in client_standard.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Charger le template v3 et la knowledge base\n",
    "with open('prompt_template_v3.md', 'r', encoding='utf-8') as f:\n",
    "    prompt_template_v3 = f.read()\n",
    "\n",
    "with open('knowledge_base.txt', 'r', encoding='utf-8') as f:\n",
    "    knowledge = f.read()\n",
    "\n",
    "# Fonction de filtrage\n",
    "def filter_knowledge_by_risk(profil_risque, knowledge_content):\n",
    "    risk_objectives = {\n",
    "        \"Prudent\": [\"PRESERVATION\", \"REVENU\"],\n",
    "        \"√âquilibr√©\": [\"REVENU\", \"CROISSANCE_MODEREE\"], \n",
    "        \"Audacieux\": [\"CROISSANCE\", \"CROISSANCE_AGGRESSIVE\"]\n",
    "    }\n",
    "    \n",
    "    relevant_objectives = risk_objectives.get(profil_risque, [\"CROISSANCE_MODEREE\"])\n",
    "    sections = knowledge_content.split(\"OBJECTIF :\")\n",
    "    filtered = []\n",
    "    \n",
    "    for section in sections[1:]:\n",
    "        section_content = \"OBJECTIF :\" + section\n",
    "        for objective in relevant_objectives:\n",
    "            if objective in section_content:\n",
    "                filtered.append(section_content)\n",
    "                break\n",
    "        if len(filtered) >= 2:\n",
    "            break\n",
    "    \n",
    "    return \"\\n\\n\".join(filtered)\n",
    "\n",
    "# G√©n√©ration du prompt\n",
    "filtered_knowledge = filter_knowledge_by_risk(client_standard[\"profil_risque\"], knowledge)\n",
    "personalized_prompt = prompt_template_v3.format(**client_standard)\n",
    "final_prompt = f\"{personalized_prompt}\\n\\nAllocations de r√©f√©rence :\\n{filtered_knowledge}\"\n",
    "\n",
    "print(f\"\\nLongueur du prompt: {len(final_prompt)} caract√®res\")\n",
    "print(f\"Sections KB utilis√©es: {len(filtered_knowledge.split('OBJECTIF :'))-1}\")\n",
    "\n",
    "# Appel Gemini\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "response = model.generate_content(final_prompt)\n",
    "\n",
    "print(\"\\n=== R√âPONSE GEMINI - TEST NORMAL ===\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da40793",
   "metadata": {},
   "source": [
    "## Partie 3 : Jeu d'Essai - 5 Profils Clients Diff√©rents\n",
    "\n",
    "Test du syst√®me d'atypicit√© avec des objectifs vari√©s pour valider les scores 1-10 et l'adaptation de l'IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa52be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeu d'essai - 5 clients avec diff√©rents niveaux d'atypicit√©\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Configuration API\n",
    "API_KEY = os.getenv('GEMINI_API_KEY', \"AIzaSyCH5PqnZ-OGuVsrSit966K0IDCfperG7u8\")\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# 5 profils clients avec objectifs de diff√©rents niveaux d'atypicit√©\n",
    "clients_test = [\n",
    "    {\n",
    "        \"nom\": \"Client 1 - Ultra-typique (Score attendu: 9-10)\",\n",
    "        \"objectif\": \"Pr√©parer ma retraite en constituant un patrimoine diversifi√©\",\n",
    "        \"profil_risque\": \"√âquilibr√©\",\n",
    "        \"montant_initial\": \"25000‚Ç¨\",\n",
    "        \"montant_mensuel\": \"500‚Ç¨\",\n",
    "        \"horizon\": \"20 ans\"\n",
    "    },\n",
    "    {\n",
    "        \"nom\": \"Client 2 - Typique avec nuance (Score attendu: 7-8)\",\n",
    "        \"objectif\": \"Constituer un patrimoine pour ma retraite en privil√©giant l'immobilier et l'investissement responsable\",\n",
    "        \"profil_risque\": \"Prudent\",\n",
    "        \"montant_initial\": \"30000‚Ç¨\",\n",
    "        \"montant_mensuel\": \"800‚Ç¨\",\n",
    "        \"horizon\": \"18 ans\"\n",
    "    },\n",
    "    {\n",
    "        \"nom\": \"Client 3 - Moyennement typique (Score attendu: 5-6)\",\n",
    "        \"objectif\": \"Financer les √©tudes de mes enfants tout en pr√©parant ma retraite avec une approche √©quilibr√©e\",\n",
    "        \"profil_risque\": \"√âquilibr√©\",\n",
    "        \"montant_initial\": \"15000‚Ç¨\",\n",
    "        \"montant_mensuel\": \"600‚Ç¨\",\n",
    "        \"horizon\": \"12 ans\"\n",
    "    },\n",
    "    {\n",
    "        \"nom\": \"Client 4 - Peu typique (Score attendu: 3-4)\",\n",
    "        \"objectif\": \"Investir uniquement dans des actifs √©thiques et durables pour financer mon tour du monde dans 8 ans\",\n",
    "        \"profil_risque\": \"Audacieux\",\n",
    "        \"montant_initial\": \"40000‚Ç¨\",\n",
    "        \"montant_mensuel\": \"1200‚Ç¨\",\n",
    "        \"horizon\": \"8 ans\"\n",
    "    },\n",
    "    {\n",
    "        \"nom\": \"Client 5 - Ultra-atypique (Score attendu: 1-2)\",\n",
    "        \"objectif\": \"G√©n√©rer des revenus passifs maximaux pour devenir financi√®rement ind√©pendant et quitter mon emploi dans 5 ans\",\n",
    "        \"profil_risque\": \"Audacieux\",\n",
    "        \"montant_initial\": \"100000‚Ç¨\",\n",
    "        \"montant_mensuel\": \"3000‚Ç¨\",\n",
    "        \"horizon\": \"5 ans\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Fonctions utilitaires\n",
    "def load_templates_and_knowledge():\n",
    "    with open('prompt_template_v3.md', 'r', encoding='utf-8') as f:\n",
    "        template = f.read()\n",
    "    with open('knowledge_base.txt', 'r', encoding='utf-8') as f:\n",
    "        knowledge = f.read()\n",
    "    return template, knowledge\n",
    "\n",
    "def filter_knowledge_by_risk(profil_risque, knowledge_content):\n",
    "    risk_objectives = {\n",
    "        \"Prudent\": [\"PRESERVATION\", \"REVENU\"],\n",
    "        \"√âquilibr√©\": [\"REVENU\", \"CROISSANCE_MODEREE\"], \n",
    "        \"Audacieux\": [\"CROISSANCE\", \"CROISSANCE_AGGRESSIVE\"]\n",
    "    }\n",
    "    \n",
    "    relevant_objectives = risk_objectives.get(profil_risque, [\"CROISSANCE_MODEREE\"])\n",
    "    sections = knowledge_content.split(\"OBJECTIF :\")\n",
    "    filtered = []\n",
    "    \n",
    "    for section in sections[1:]:\n",
    "        section_content = \"OBJECTIF :\" + section\n",
    "        for objective in relevant_objectives:\n",
    "            if objective in section_content:\n",
    "                filtered.append(section_content)\n",
    "                break\n",
    "        if len(filtered) >= 2:\n",
    "            break\n",
    "    \n",
    "    return \"\\n\\n\".join(filtered)\n",
    "\n",
    "def test_client(client_data, template, knowledge):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST: {client_data['nom']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Objectif: {client_data['objectif']}\")\n",
    "    print(f\"Profil: {client_data['profil_risque']}\")\n",
    "    print(f\"Montant initial: {client_data['montant_initial']}\")\n",
    "    print(f\"√âpargne mensuelle: {client_data['montant_mensuel']}\")\n",
    "    print(f\"Horizon: {client_data['horizon']}\")\n",
    "    \n",
    "    # Pr√©paration du prompt\n",
    "    filtered_knowledge = filter_knowledge_by_risk(client_data[\"profil_risque\"], knowledge)\n",
    "    personalized_prompt = template.format(**client_data)\n",
    "    final_prompt = f\"{personalized_prompt}\\n\\nAllocations de r√©f√©rence :\\n{filtered_knowledge}\"\n",
    "    \n",
    "    print(f\"\\nLongueur prompt: {len(final_prompt)} caract√®res\")\n",
    "    \n",
    "    # Appel Gemini\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
    "    response = model.generate_content(final_prompt)\n",
    "    \n",
    "    # Extraction du score d'atypicit√© de la r√©ponse (si pr√©sent)\n",
    "    response_text = response.text\n",
    "    if \"Score attribu√©\" in response_text:\n",
    "        lines = response_text.split('\\n')\n",
    "        for line in lines:\n",
    "            if \"Score attribu√©\" in line:\n",
    "                print(f\"‚úÖ {line.strip()}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nüìä R√âPONSE (premiers 400 caract√®res):\")\n",
    "    print(response_text[:400] + \"...\" if len(response_text) > 400 else response_text)\n",
    "    print(f\"\\nüîç Recherche de mots-cl√©s d'adaptation:\")\n",
    "    \n",
    "    # Analyse rapide du niveau d'adaptation\n",
    "    adaptation_keywords = [\"strictement\", \"adapter\", \"personnalis√©\", \"d√©vier\", \"ajuster\"]\n",
    "    found_keywords = [kw for kw in adaptation_keywords if kw.lower() in response_text.lower()]\n",
    "    if found_keywords:\n",
    "        print(f\"Mots-cl√©s trouv√©s: {', '.join(found_keywords)}\")\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "# Ex√©cution des tests\n",
    "print(\"üöÄ D√âBUT DU JEU D'ESSAI - 5 CLIENTS DIFF√âRENTS\")\n",
    "print(\"Objectif: Valider le syst√®me de score d'atypicit√© et l'adaptation de l'IA\")\n",
    "\n",
    "template, knowledge = load_templates_and_knowledge()\n",
    "\n",
    "# Test de chaque client\n",
    "results = []\n",
    "for client in clients_test:\n",
    "    try:\n",
    "        result = test_client(client, template, knowledge)\n",
    "        results.append({\"client\": client[\"nom\"], \"success\": True, \"response_length\": len(result)})\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERREUR pour {client['nom']}: {str(e)}\")\n",
    "        results.append({\"client\": client[\"nom\"], \"success\": False, \"error\": str(e)})\n",
    "\n",
    "# R√©sum√© final\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìã R√âSUM√â DU JEU D'ESSAI\")\n",
    "print(f\"{'='*60}\")\n",
    "for result in results:\n",
    "    status = \"‚úÖ OK\" if result[\"success\"] else \"‚ùå ERREUR\"\n",
    "    length = f\"({result.get('response_length', 0)} car.)\" if result[\"success\"] else \"\"\n",
    "    print(f\"{status} {result['client']} {length}\")\n",
    "\n",
    "print(f\"\\nüéØ Tests r√©ussis: {sum(1 for r in results if r['success'])}/{len(results)}\")\n",
    "print(\"‚úÖ JEU D'ESSAI TERMIN√â\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
